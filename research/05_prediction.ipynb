{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f7f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e393acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/satwik/Downloads/MLproj/airlines_sentiment_classification/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf8a6c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa9d2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/satwik/Downloads/MLproj/airlines_sentiment_classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fd0f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.24:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [11/Aug/2025 03:34:24] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Aug/2025 03:34:25] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [11/Aug/2025 03:34:26] \"GET /predict HTTP/1.1\" 404 -\n",
      "192.168.1.24 - - [11/Aug/2025 03:34:44] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.24 - - [11/Aug/2025 03:34:44] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [11/Aug/2025 03:36:08] \"GET /predict HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from flask import Flask\n",
    "from flask import Flask, request, jsonify, render_template_string\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize  the Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "#Your SentimentInference class\n",
    "class SentimentInference:\n",
    "    def __init__(self, model_path: str):\n",
    "        \"\"\"\n",
    "        Initializes the SentimentInference class.\n",
    "\n",
    "        Args:\n",
    "            model_path (str): Path to the trained model and tokenizer.\n",
    "        \"\"\"\n",
    "        self.model_path = Path(model_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n",
    "        self.sentiment_map = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "    def predict_sentiment(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Predicts the sentiment of the input text.\n",
    "\n",
    "        Args:\n",
    "            text (str): Input text for sentiment prediction.\n",
    "\n",
    "        Returns:\n",
    "            str: Predicted sentiment ('negative', 'neutral', 'positive').\n",
    "        \"\"\"\n",
    "\n",
    "        #Tokenize the input text \n",
    "        inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = self.model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(predictions, dim=1).item()\n",
    "\n",
    "        # Map the predicted class to Sentiment\n",
    "        return self.sentiment_map[predicted_class]\n",
    "\n",
    "\n",
    "# Initialize the SentimentInference class\n",
    "model_path = \"/Users/satwik/Downloads/MLproj/airlines_sentiment_classification/artifacts/training/trained_model\"\n",
    "sentiment_inference = SentimentInference(model_path)\n",
    "\n",
    "# Home page route\n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def home():\n",
    "    return \"\"\"\n",
    "    <h1>Welcome to Sentiment Analysis / Test Classification</h1>\n",
    "    <p>Click <a href=\"/predict\">here</a> to go to the prediction page.</p>\n",
    "    \"\"\"\n",
    "\n",
    "# Predict page route\n",
    "def predict():\n",
    "    if request.method == \"GET\":\n",
    "        # Render a basic HTML form for text input\n",
    "        return render_template_string('''\n",
    "        <h1>Sentiment Prediction</h1>\n",
    "        <form method=\"POST\">\n",
    "            <label for=\"text\">Enter your text:</label><br>\n",
    "            <textarea id=\"text\" name=\"text\" rows=\"4\" cols=\"50\"></textarea><br><br>\n",
    "            <input type=\"submit\" value=\"Predict\">\n",
    "        </form>\n",
    "        ''')\n",
    "    elif request.method == 'POST':\n",
    "        # Get the input text from the form\n",
    "        text = request.form.get(\"text\")\n",
    "         \n",
    "        # Validate the input\n",
    "        if not text:\n",
    "            return jsonify({\"error\": \" No text provided\"}), 400\n",
    "        \n",
    "        # predict the sentiment\n",
    "        try:\n",
    "            sentiment = sentiment_inference.predict_sentiment(text)\n",
    "            return jsonify({\"sentiment\": sentiment})\n",
    "\n",
    "        except Exception as e:\n",
    "            return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the flask app\n",
    "    app.run(host=\"0.0.0.0\", port=5000)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda6d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "#Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class PredictionPipeline:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the PredictionPipeline class.\n",
    "        \"\"\"\n",
    "        self.model_path = Path(\"artifacts/training/trained_model\") # Path to trained model\n",
    "        self.sentiment_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "\n",
    "        #Debug: print the model path\n",
    "        if not self.model_path.exists():\n",
    "            raise FileNotFoundError(f\"Model path does not exist: {self.model_path}\")\n",
    "\n",
    "        self.load_model()\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Loads the trained model and tokenizer\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_path)\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading model or tokenizer: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    def predict(self, text: str) -> str:\n",
    "        \"\"\" \n",
    "        Predicts the sentiment of the input text\n",
    "\n",
    "        Args:\n",
    "            text(str): Input text for Sentiment prediction.\n",
    "        \n",
    "        Returns:\n",
    "            str: Predicted sentiment ('negative', 'neutral', 'positive').\n",
    "        \"\"\"\n",
    "    \n",
    "        try:\n",
    "            #Tokenize the input text\n",
    "            inputs = self.tokenizer(text, return_tensors='pt', paddding=True, truncation=True, max_length=128)\n",
    "\n",
    "            #Get model predictions\n",
    "            outputs = self.model(**inputs)\n",
    "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            predicted_class = torch.argmax(predictions, dim=1).item()\n",
    "\n",
    "\n",
    "            #Map the predicted class to sentiment\n",
    "            return self.sentiment_map[predicted_class]\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during prediction: {e}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eec7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a172095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: model.safetensors\n",
      "Copied: tokenizer_config.json\n",
      "Copied: special_tokens_map.json\n",
      "Copied: config.json\n",
      "Copied: tokenizer.json\n",
      "Copied: training_args.bin\n",
      "Copied: vocab.txt\n",
      "All files copied successfully.\n"
     ]
    }
   ],
   "source": [
    "import shutil \n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "#Define source and destination paths\n",
    "source_dir = Path(\"/Users/satwik/Downloads/MLproj/airlines_sentiment_classification/artifacts/training/trained_model\")\n",
    "destination_dir = Path(\"model\")\n",
    "\n",
    "# Create the destination folder if it doesn't exist\n",
    "destination_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#Copy files\n",
    "for file in source_dir.iterdir():\n",
    "    if file.is_file():\n",
    "        shutil.copy(file, destination_dir / file.name)\n",
    "        print(f\"Copied: {file.name}\")\n",
    "\n",
    "print(\"All files copied successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64e06c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_envv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
